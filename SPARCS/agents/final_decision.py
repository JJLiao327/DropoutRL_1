from typing import List, Any, Dict

from SPARCS.graph.node import Node
from SPARCS.agents.agent_registry import AgentRegistry
from SPARCS.llm.llm_registry import LLMRegistry
from SPARCS.prompt.prompt_set_registry import PromptSetRegistry
from SPARCS.tools.coding.python_executor import PyExecutor


@AgentRegistry.register('FinalWriteCode')
class FinalWriteCode(Node):
    def __init__(self, id: str | None = None, domain: str = "", llm_name: str = ""):
        super().__init__(id, "FinalWriteCode", domain, llm_name)
        self.llm = LLMRegistry.get(llm_name)
        self.prompt_set = PromptSetRegistry.get(domain)

    def extract_example(self, prompt: Dict[str, str]) -> list:
        prompt = prompt['task']
        lines = (line.strip() for line in prompt.split('\n') if line.strip())
        results = []
        lines_iter = iter(lines)
        for line in lines_iter:
            if line.startswith('>>>'):
                function_call = line[4:]
                expected_output = next(lines_iter, None)
                if expected_output:
                    results.append(f"assert {function_call} == {expected_output}")
        return results

    def _process_inputs(self, raw_inputs: Dict[str, str], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        self.role = self.prompt_set.get_decision_role()
        self.constraint = self.prompt_set.get_decision_constraint()
        system_prompt = f"{self.role}.\n {self.constraint}"
        spatial_str = ""
        for id, info in spatial_info.items():
            if info['output'].startswith("```python") and info['output'].endswith("```"):
                self.internal_tests = self.extract_example(raw_inputs)
                output = info['output'].lstrip("```python\n").rstrip("\n```")
                is_solved, feedback, state = PyExecutor().execute(output, self.internal_tests, timeout=10)
                spatial_str += f"Agent {id} as a {info['role']}:\n\nThe code written by the agent is:\n\n{info['output']}\n\n Whether it passes internal testing? {is_solved}.\n\nThe feedback is:\n\n {feedback}.\n\n"
            else:
                spatial_str += f"Agent {id} as a {info['role']} provides the following info: {info['output']}\n\n"
        user_prompt = f"The task is:\n\n{raw_inputs[0]['task']}.\n At the same time, the outputs and feedbacks of other agents are as follows:\n\n{spatial_str}\n\n"
        return [system_prompt, user_prompt]

    def _run_llm_sync(self, processed_inputs: List[Any], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        system_prompt, user_prompt = processed_inputs
        message = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': user_prompt}]
        try:
            response = self.llm.gen(message)
            return [response if response else "<EMPTY>"]
        except Exception as e:
            return [f"<ERROR in FinalWriteCode: {str(e)}>"]


@AgentRegistry.register('FinalRefer')
class FinalRefer(Node):
    def __init__(self, id: str | None = None, domain: str = "", llm_name: str = ""):
        super().__init__(id, "FinalRefer", domain, llm_name)
        self.llm = LLMRegistry.get(llm_name)
        self.prompt_set = PromptSetRegistry.get(domain)

    def _process_inputs(self, raw_inputs: Dict[str, str], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        self.role = self.prompt_set.get_decision_role()
        self.constraint = self.prompt_set.get_decision_constraint()
        system_prompt = f"{self.role}.\n {self.constraint}"
        spatial_str = ""
        for id, info in spatial_info.items():
            spatial_str += id + ": " + info['output'] + "\n\n"
        decision_few_shot = self.prompt_set.get_decision_few_shot()
        user_prompt = f"{decision_few_shot} The task is:\n\n {raw_inputs[0]['task']}.\n At the same time, the output of other agents is as follows:\n\n{spatial_str}"
        return [system_prompt, user_prompt]

    def _run_llm_sync(self, processed_inputs: List[Any], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        system_prompt, user_prompt = processed_inputs
        message = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': user_prompt}]
        try:
            response = self.llm.gen(message)
            return [response if response else "<EMPTY>"]
        except Exception as e:
            return [f"<ERROR in FinalRefer: {str(e)}>"]


@AgentRegistry.register('FinalDirect')
class FinalDirect(Node):
    def __init__(self, id: str | None = None, domain: str = "", llm_name: str = ""):
        super().__init__(id, "FinalDirect", domain, llm_name)
        self.prompt_set = PromptSetRegistry.get(domain)

    def _process_inputs(self, raw_inputs: Dict[str, str], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        return ["", ""]  # dummy

    def _run_llm_sync(self, processed_inputs: List[Any], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        output = ""
        info_list = [info['output'] for info in spatial_info.values()]
        if info_list:
            output = info_list[-1]
        return [output]


@AgentRegistry.register('FinalMajorVote')
class FinalMajorVote(Node):
    def __init__(self, id: str | None = None, domain: str = "", llm_name: str = ""):
        super().__init__(id, "FinalMajorVote", domain, llm_name)
        self.prompt_set = PromptSetRegistry.get(domain)

    def _process_inputs(self, raw_inputs: Dict[str, str], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        return ["", ""]  # dummy

    def _run_llm_sync(self, processed_inputs: List[Any], spatial_info: Dict[str, Any], temporal_info: Dict[str, Any], **kwargs) -> List[Any]:
        output_num = {}
        max_output = ""
        max_output_num = 0
        for info in spatial_info.values():
            processed_output = self.prompt_set.postprocess_answer(info['output'])
            output_num[processed_output] = output_num.get(processed_output, 0) + 1
            if output_num[processed_output] > max_output_num:
                max_output = processed_output
                max_output_num = output_num[processed_output]
        return [max_output]
